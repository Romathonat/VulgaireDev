{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will implement the algorithm of the Apriori algorithm as described in \"Fast algorithms for mining association rules\", Rakesh Agrawal, Ramakrishnan Srikant.\n",
    "\n",
    "First we will try a dummy implementation, then we will try to use correct data-structures.\n",
    "\n",
    "## Naive approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>...</th>\n",
       "      <th>0.38</th>\n",
       "      <th>0.39</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.45</th>\n",
       "      <th>0.46</th>\n",
       "      <th>0.47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...   0.38  0.39  0.40  \\\n",
       "0  0    0    0    0    0    0    0    1    0    0  ...      0     0     0   \n",
       "1  0    0    0    1    0    0    0    0    0    0  ...      0     0     1   \n",
       "2  0    0    0    0    0    1    0    0    0    0  ...      0     0     0   \n",
       "3  0    0    0    0    0    0    1    0    0    0  ...      0     0     1   \n",
       "4  0    0    1    0    1    0    0    0    0    0  ...      0     0     0   \n",
       "5  0    0    0    0    0    0    0    0    0    0  ...      1     0     0   \n",
       "6  0    0    1    1    0    0    0    0    0    0  ...      0     0     0   \n",
       "7  0    0    0    0    0    0    0    0    0    0  ...      0     0     0   \n",
       "8  0    0    0    0    0    0    0    0    0    0  ...      0     0     0   \n",
       "9  0    0    0    0    0    0    0    0    0    0  ...      0     0     0   \n",
       "\n",
       "   0.41  0.42  0.43  0.44  0.45  0.46  0.47  \n",
       "0     0     0     1     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     1     0     0  \n",
       "3     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0  \n",
       "5     0     0     0     0     0     0     0  \n",
       "6     0     0     0     0     0     0     0  \n",
       "7     0     0     0     0     0     0     0  \n",
       "8     0     1     1     0     0     0     0  \n",
       "9     0     0     0     0     0     1     1  \n",
       "\n",
       "[10 rows x 50 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "df = pd.read_csv('./data.csv')\n",
    "df = df.drop('1', 1)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SUPP = 0.05\n",
    "MIN_CONF = 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_frequent(itemset, min_supp):\n",
    "    count = 0\n",
    "    for _, row in df.iterrows():\n",
    "        is_line_valid = True\n",
    "        for item in itemset:\n",
    "            if row[item] == 0:\n",
    "                is_line_valid = False\n",
    "        \n",
    "        if is_line_valid:\n",
    "            count += 1\n",
    "    frequency = count/df[\"0\"].count()\n",
    "    \n",
    "    if frequency >= min_supp:\n",
    "        return True\n",
    "    \n",
    "    return False      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [{'0'}, {'0.1'}, {'0.2'}, {'0.3'}, {'0.4'}, {'0.5'}, {'0.7'}, {'0.9'}, {'1.1'}, {'0.11'}, {'0.13'}, {'0.14'}, {'0.15'}, {'0.16'}, {'0.17'}, {'0.18'}, {'0.20'}, {'0.21'}, {'0.22'}, {'0.25'}, {'0.26'}, {'0.27'}, {'0.29'}, {'0.30'}, {'0.31'}, {'0.33'}, {'0.34'}, {'0.35'}, {'0.38'}, {'0.39'}, {'0.40'}, {'0.41'}, {'0.42'}, {'0.43'}, {'0.44'}, {'0.45'}, {'0.46'}, {'0.47'}]}\n"
     ]
    }
   ],
   "source": [
    "def itemset_1_frequent(df, min_supp):\n",
    "    sum_column = df.sum()\n",
    "    result = []\n",
    "    \n",
    "    for index, count in sum_column.items():\n",
    "        if count/df[\"0\"].count() > min_supp:\n",
    "            result.append(set([index]))\n",
    "            \n",
    "    return result\n",
    "\n",
    "itemsets = {} # dict of lists of sets\n",
    "itemsets[1] = itemset_1_frequent(df, MIN_SUPP)\n",
    "print(itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'1', '2', '3', '4'})}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apriori_gen(itemsets):\n",
    "    # simple approach, not the one on the paper\n",
    "    # it works but does not seem as optimized as the paper approach\n",
    "    items = set()\n",
    "    for x_itemset in itemsets:\n",
    "        for item in x_itemset:\n",
    "            items.add(item)\n",
    "    \n",
    "    C_k = set()\n",
    "    \n",
    "    for x_itemset in itemsets:\n",
    "        for item in items:  \n",
    "            if item not in x_itemset:\n",
    "                C_k.add(frozenset([*x_itemset, item]))          \n",
    "    \n",
    "    elt_to_remove = set()\n",
    "    \n",
    "    for x_itemset in C_k:        \n",
    "        for elt in x_itemset:\n",
    "            subset = set([*x_itemset])\n",
    "            subset.remove(elt)\n",
    "            if subset not in itemsets:\n",
    "                elt_to_remove.add(x_itemset)\n",
    "        \n",
    "    for remove in elt_to_remove:\n",
    "        C_k.remove(remove)\n",
    "   \n",
    "    return C_k\n",
    "            \n",
    "            \n",
    "apriori_gen([{'1', '2', '3'}, {'1', '2', '4'}, {'1', '3', '4'}, {'1', '3', '5'}, {'2', '3', '4'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In aPriori, the are three ways of stating that an itemset is infrequent. It could be because:\n",
    "  - it is not generated (in the first part of apriori_gen)\n",
    "  - it is pruned (second part of apriori_gen, based on the fact that if the itemset {beer} is non-frequent, the itemset {beer, milk} is non-frequent too)\n",
    "  - it does not have minimum support (we count in data)\n",
    " \n",
    "With the approach here, the number of generated itemsets is greater than the one on the paper, leading to a diminution of performances.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{frozenset({'0.7', '0.35'})}\n"
     ]
    }
   ],
   "source": [
    "def subset(candidates, row):\n",
    "    \"\"\" Filter all candidates itemset wich are present in the row\n",
    "    \"\"\"\n",
    "    # dummy solution\n",
    "    subset = set()\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        add = True\n",
    "        for elt in candidate:\n",
    "            if not row[elt]:\n",
    "                add = False\n",
    "        \n",
    "        if add:\n",
    "            subset.add(frozenset(candidate))\n",
    "            \n",
    "    return subset\n",
    "\n",
    "candidates = [{'0.7', '0.35'}, {'0', '0.1'}]\n",
    "row = next(df.iterrows())[1]\n",
    "print(subset(candidates, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [{'0'}, {'0.1'}, {'0.2'}, {'0.3'}, {'0.4'}, {'0.5'}, {'0.7'}, {'0.9'}, {'1.1'}, {'0.11'}, {'0.13'}, {'0.14'}, {'0.15'}, {'0.16'}, {'0.17'}, {'0.18'}, {'0.20'}, {'0.21'}, {'0.22'}, {'0.25'}, {'0.26'}, {'0.27'}, {'0.29'}, {'0.30'}, {'0.31'}, {'0.33'}, {'0.34'}, {'0.35'}, {'0.38'}, {'0.39'}, {'0.40'}, {'0.41'}, {'0.42'}, {'0.43'}, {'0.44'}, {'0.45'}, {'0.46'}, {'0.47'}], 2: [frozenset({'0.25', '0.26'}), frozenset({'0.17', '0.33'})]}\n",
      "APriori took 699.8140921592712 seconds\n"
     ]
    }
   ],
   "source": [
    "def aPriori():\n",
    "    itemsets = {} # dict of lists of sets\n",
    "    itemsets[1] = itemset_1_frequent(df, MIN_SUPP)\n",
    "    last_itemset = itemsets[1] \n",
    "    itemset_size = 1\n",
    "\n",
    "    while(last_itemset):\n",
    "        itemset_size += 1\n",
    "\n",
    "        candidates = apriori_gen(last_itemset)\n",
    "        candidates_count = {}\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            # print(row)\n",
    "            local_candidates = subset(candidates, row)\n",
    "            for local_candidate in local_candidates:\n",
    "                candidates_count[id(local_candidate)] = candidates_count.get(id(local_candidate), 0) + 1\n",
    "\n",
    "\n",
    "        # check minimum support\n",
    "        for candidate in candidates:\n",
    "            if candidates_count[id(candidate)]/df[\"0\"].count() > MIN_SUPP:\n",
    "                itemsets.setdefault(itemset_size, []).append(candidate)\n",
    "\n",
    "        last_itemset = itemsets.get(itemset_size, 0)\n",
    "\n",
    "    return itemsets\n",
    "\n",
    "print(aPriori())\n",
    "\n",
    "# let's print the time it takes with this approach\n",
    "\n",
    "start_time = time.time()\n",
    "aPriori()\n",
    "print(\"APriori took {} seconds\".format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 1994, databases accesses were costly. Today, a dataset of this size fits in RAM. So instead of taking each row, and extracting subsets, we can take each itemset, and count the number of occurences. Theoriticaly complexities are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [{'0'}, {'0.1'}, {'0.2'}, {'0.3'}, {'0.4'}, {'0.5'}, {'0.7'}, {'0.9'}, {'1.1'}, {'0.11'}, {'0.13'}, {'0.14'}, {'0.15'}, {'0.16'}, {'0.17'}, {'0.18'}, {'0.20'}, {'0.21'}, {'0.22'}, {'0.25'}, {'0.26'}, {'0.27'}, {'0.29'}, {'0.30'}, {'0.31'}, {'0.33'}, {'0.34'}, {'0.35'}, {'0.38'}, {'0.39'}, {'0.40'}, {'0.41'}, {'0.42'}, {'0.43'}, {'0.44'}, {'0.45'}, {'0.46'}, {'0.47'}], 2: [frozenset({'0.25', '0.26'}), frozenset({'0.17', '0.33'})]}\n",
      "APrioriRAM took 9.511401653289795 seconds\n"
     ]
    }
   ],
   "source": [
    "def aPrioriRAM():\n",
    "    itemsets = {} # dict of lists of sets\n",
    "    itemsets[1] = itemset_1_frequent(df, MIN_SUPP)\n",
    "    last_itemset = itemsets[1] \n",
    "    itemset_size = 1\n",
    "    \n",
    "    row_list = []\n",
    "    \n",
    "    # each row becomes a dict\n",
    "    for index, row in df.iterrows():\n",
    "        elements = []      \n",
    "        \n",
    "        for header, value in row.iteritems():\n",
    "            if value == 1:\n",
    "                elements.append(header)\n",
    "\n",
    "        row_list.append(frozenset(elements))\n",
    "    \n",
    "    while(last_itemset):\n",
    "        itemset_size += 1\n",
    "\n",
    "        candidates = apriori_gen(last_itemset)\n",
    "        for candidate in candidates:\n",
    "            count = 0\n",
    "            \n",
    "            for row in row_list:                        \n",
    "                if candidate.issubset(row):\n",
    "                    count = count + 1          \n",
    "            \n",
    "            if count/df[\"0\"].count() > MIN_SUPP:\n",
    "                itemsets.setdefault(itemset_size, []).append(candidate)\n",
    "\n",
    "        last_itemset = itemsets.get(itemset_size, 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    return itemsets\n",
    "\n",
    "       \n",
    "start_time = time.time()\n",
    "print(aPrioriRAM())\n",
    "print(\"APrioriRAM took {} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is better ! In fact, with this version we use python set, and we use set operations wich are more performant (https://stackoverflow.com/questions/27674289/the-complextiy-of-python-issubset) in python that what I did previously. Indeed, it is faster to just check if item's names are in another set (O(1), depending if colision on the hashtable), instead of doing it on a panda serie (O(n)) like I did previously with this line:\n",
    "```python\n",
    "if not row[elt]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'1', '2', '3', '4'})}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we redefine apriori_gen in order to be closer to the paper\n",
    "# this function need to keep the order or element in sets !\n",
    "# we could try with an orderedSet, but we don't have that by default in python\n",
    "# we will just convert itemsets to sorted list\n",
    "def apriori_gen(itemsets):\n",
    "    sorted_itemsets = []\n",
    "    for itemset in itemsets:\n",
    "        sorted_itemsets.append(sorted(list(itemset)))\n",
    "        \n",
    "    C_k = set()\n",
    "    \n",
    "    for itemset1 in sorted_itemsets:\n",
    "        for itemset2 in sorted_itemsets:\n",
    "            if itemset2[:-1] == itemset1[:-1] and itemset2[-1] != itemset1[-1]:\n",
    "                \n",
    "                C_k.add(frozenset(itemset1+ [itemset2[-1]]))\n",
    "    \n",
    "    elt_to_remove = set()\n",
    "    \n",
    "    for x_itemset in C_k:        \n",
    "        for elt in x_itemset:\n",
    "            subset = set([*x_itemset])\n",
    "            subset.remove(elt)\n",
    "            if subset not in itemsets:\n",
    "                elt_to_remove.add(x_itemset)\n",
    "        \n",
    "    for remove in elt_to_remove:\n",
    "        C_k.remove(remove)\n",
    "\n",
    "    return C_k\n",
    "                \n",
    "apriori_gen([{'1', '2', '3'}, {'1', '2', '4'}, {'1', '3', '4'}, {'1', '3', '5'}, {'2', '3', '4'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [{'0'}, {'0.1'}, {'0.2'}, {'0.3'}, {'0.4'}, {'0.5'}, {'0.7'}, {'0.9'}, {'1.1'}, {'0.11'}, {'0.13'}, {'0.14'}, {'0.15'}, {'0.16'}, {'0.17'}, {'0.18'}, {'0.20'}, {'0.21'}, {'0.22'}, {'0.25'}, {'0.26'}, {'0.27'}, {'0.29'}, {'0.30'}, {'0.31'}, {'0.33'}, {'0.34'}, {'0.35'}, {'0.38'}, {'0.39'}, {'0.40'}, {'0.41'}, {'0.42'}, {'0.43'}, {'0.44'}, {'0.45'}, {'0.46'}, {'0.47'}], 2: [frozenset({'0.25', '0.26'}), frozenset({'0.17', '0.33'})]}\n",
      "APrioriRAM took 9.233964681625366 seconds\n"
     ]
    }
   ],
   "source": [
    "# Now we check if this new approach is better\n",
    "start_time = time.time()\n",
    "print(aPrioriRAM())\n",
    "print(\"APrioriRAM took {} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see my two implementations of apriori_gen are producing similar results. Theoriticaly, the second should be better, because it generates less candidates in the first part. In fact, I don't have databases optimizations to make an efficient SQL query like in the paper, so my implementation is not optimal (self join in O(n^2) ...).\n",
    "\n",
    "### Discovering rules\n",
    "\n",
    "Now that we have mined frequent itemsets, we can now extract associations rules.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6271\n",
      "[[frozenset({'0.26'}), {'0.25'}], [frozenset({'0.25'}), {'0.26'}]]\n"
     ]
    }
   ],
   "source": [
    "row_list = []\n",
    "    \n",
    "for index, row in df.iterrows():\n",
    "    elements = []      \n",
    "\n",
    "    for header, value in row.iteritems():\n",
    "        if value == 1:\n",
    "            elements.append(header)\n",
    "\n",
    "    row_list.append(frozenset(elements))\n",
    "\n",
    "def support(_itemset):\n",
    "    count = 0\n",
    "    for row in row_list:     \n",
    "        if _itemset.issubset(row):\n",
    "            count = count + 1     \n",
    "            \n",
    "    return count\n",
    "\n",
    "a = set()\n",
    "a.add('0.1')\n",
    "print(support(a))    \n",
    "        \n",
    "\n",
    "def gen_rules(l_k, a_m, rules):\n",
    "    subsets = set()\n",
    "       \n",
    "    local_subsets = list(combinations(a_m, len(a_m)-1))\n",
    "    for subset in local_subsets:\n",
    "        subsets.add(frozenset(subset))\n",
    "    \n",
    "    for subset in subsets:\n",
    "        try:\n",
    "            conf = support(l_k)/support(subset)\n",
    "        except ZeroDivisionError:\n",
    "            conf = 0\n",
    "            \n",
    "        if conf > MIN_CONF:\n",
    "            rules.append([subset, l_k.difference(subset)])\n",
    "            if len(subset) - 1 > 1:\n",
    "                gen_rules(l_k, subsets)\n",
    "                \n",
    "rules = []\n",
    "gen_rules({'0.25', '0.26'}, {'0.25', '0.26'}, rules)\n",
    "print(rules)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can have our final code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules:\n",
      "frozenset({'0.7', '1.1'}) => frozenset({'0.35'})\n",
      "frozenset({'0.7', '0.35'}) => frozenset({'1.1'})\n",
      "frozenset({'1.1', '0.35'}) => frozenset({'0.7'})\n",
      "frozenset({'0.3', '0.17'}) => frozenset({'0.33'})\n",
      "frozenset({'0.3', '0.33'}) => frozenset({'0.17'})\n",
      "frozenset({'0.17', '0.33'}) => frozenset({'0.3'})\n",
      "frozenset({'0.30', '0.43'}) => frozenset({'0.15'})\n",
      "frozenset({'0.15', '0.30'}) => frozenset({'0.43'})\n",
      "frozenset({'0.15', '0.43'}) => frozenset({'0.30'})\n",
      "frozenset({'0.44', '0'}) => frozenset({'0.2'})\n",
      "frozenset({'0.2', '0'}) => frozenset({'0.44'})\n",
      "frozenset({'0.2', '0.44'}) => frozenset({'0'})\n",
      "APrioriRAM took 13.434985160827637 seconds\n"
     ]
    }
   ],
   "source": [
    "MIN_SUPP = 0.03\n",
    "MIN_CONF = 0.7\n",
    "\n",
    "row_list = []\n",
    "    \n",
    "for index, row in df.iterrows():\n",
    "    elements = []      \n",
    "\n",
    "    for header, value in row.iteritems():\n",
    "        if value == 1:\n",
    "            elements.append(header)\n",
    "\n",
    "    row_list.append(frozenset(elements))\n",
    "    \n",
    "    \n",
    "def is_frequent(itemset, min_supp):\n",
    "    count = 0\n",
    "    for _, row in df.iterrows():\n",
    "        is_line_valid = True\n",
    "        for item in itemset:\n",
    "            if row[item] == 0:\n",
    "                is_line_valid = False\n",
    "        \n",
    "        if is_line_valid:\n",
    "            count += 1\n",
    "    frequency = count/df[\"0\"].count()\n",
    "    \n",
    "    if frequency >= min_supp:\n",
    "        return True\n",
    "    \n",
    "    return False      \n",
    "\n",
    "def itemset_1_frequent(df, min_supp):\n",
    "    sum_column = df.sum()\n",
    "    result = []\n",
    "    \n",
    "    for index, count in sum_column.items():\n",
    "        if count/df[\"0\"].count() > min_supp:\n",
    "            result.append(set([index]))\n",
    "            \n",
    "    return result\n",
    "\n",
    "def apriori_gen(itemsets):\n",
    "    sorted_itemsets = []\n",
    "    for itemset in itemsets:\n",
    "        sorted_itemsets.append(sorted(list(itemset)))\n",
    "        \n",
    "    C_k = set()\n",
    "    \n",
    "    for itemset1 in sorted_itemsets:\n",
    "        for itemset2 in sorted_itemsets:\n",
    "            if itemset2[:-1] == itemset1[:-1] and itemset2[-1] != itemset1[-1]:\n",
    "                \n",
    "                C_k.add(frozenset(itemset1+ [itemset2[-1]]))\n",
    "    \n",
    "    elt_to_remove = set()\n",
    "    \n",
    "    for x_itemset in C_k:        \n",
    "        for elt in x_itemset:\n",
    "            subset = set([*x_itemset])\n",
    "            subset.remove(elt)\n",
    "            if subset not in itemsets:\n",
    "                elt_to_remove.add(x_itemset)\n",
    "        \n",
    "    for remove in elt_to_remove:\n",
    "        C_k.remove(remove)\n",
    "\n",
    "    return C_k\n",
    "\n",
    "def support(_itemset):\n",
    "    count = 0\n",
    "    for row in row_list:     \n",
    "        if _itemset.issubset(row):\n",
    "            count = count + 1     \n",
    "            \n",
    "    return count\n",
    "        \n",
    "\n",
    "def gen_rules(l_k, a_m, rules):\n",
    "    subsets = set()\n",
    "       \n",
    "    local_subsets = list(combinations(a_m, len(a_m)-1))\n",
    "    for subset in local_subsets:\n",
    "        subsets.add(frozenset(subset))\n",
    "    \n",
    "    for subset in subsets:\n",
    "        try:\n",
    "            conf = support(l_k)/support(subset)\n",
    "        except ZeroDivisionError:\n",
    "            conf = 0\n",
    "            \n",
    "        if conf > MIN_CONF:\n",
    "            rules.append([subset, l_k.difference(subset)])\n",
    "            if len(subset) - 1 > 1:\n",
    "                gen_rules(l_k, subsets)\n",
    "                \n",
    "def aPrioriRAM():\n",
    "    itemsets = {} # dict of lists of sets\n",
    "    itemsets[1] = itemset_1_frequent(df, MIN_SUPP)\n",
    "    last_itemset = itemsets[1] \n",
    "    itemset_size = 1\n",
    "    \n",
    "    row_list = []\n",
    "    \n",
    "    # each row becomes a dict\n",
    "    for index, row in df.iterrows():\n",
    "        elements = []      \n",
    "        \n",
    "        for header, value in row.iteritems():\n",
    "            if value == 1:\n",
    "                elements.append(header)\n",
    "\n",
    "        row_list.append(frozenset(elements))\n",
    "    \n",
    "    while(last_itemset):\n",
    "        itemset_size += 1\n",
    "\n",
    "        candidates = apriori_gen(last_itemset)\n",
    "        for candidate in candidates:\n",
    "            count = 0\n",
    "            \n",
    "            for row in row_list:                        \n",
    "                if candidate.issubset(row):\n",
    "                    count = count + 1          \n",
    "            \n",
    "            if count/df[\"0\"].count() > MIN_SUPP:\n",
    "                itemsets.setdefault(itemset_size, []).append(candidate)\n",
    "\n",
    "        last_itemset = itemsets.get(itemset_size, 0)\n",
    "    \n",
    "    rules = []\n",
    "    for k, itemset in itemsets.items():\n",
    "        if k >= 2:\n",
    "            for itemset_local in itemset:\n",
    "                gen_rules(itemset_local, itemset_local, rules)\n",
    "        \n",
    "    return rules\n",
    "\n",
    "start_time = time.time()\n",
    "rules = aPrioriRAM()\n",
    "\n",
    "print(\"Rules:\")\n",
    "\n",
    "for rule in rules:\n",
    "    print(\"{} => {}\".format(rule[0], rule[1]))\n",
    "\n",
    "print(\"APrioriRAM took {} seconds\".format(time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
